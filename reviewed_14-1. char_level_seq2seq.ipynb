{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리뷰완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNksHfLkf5l6"
   },
   "source": [
    "이 코드는 2021년 12월 14일에 tensorflow 2.7 버전으로 마지막으로 테스트 되었습니다.  \n",
    "\n",
    "이 코드는 위키독스 '딥 러닝을 이용한 자연어 처리 입문'의 seq2seq 튜토리얼입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoEgIOcFhccg"
   },
   "source": [
    "링크 : https://wikidocs.net/24996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:49:25.728373Z",
     "start_time": "2024-06-26T13:49:25.718555Z"
    },
    "id": "IfN4gZMKh0yc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:48:12.019970Z",
     "start_time": "2024-06-26T13:48:11.987035Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "u96cUwlDgItj",
    "outputId": "82add0e2-d406-46f9-8694-6b32a2d640d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:51:17.542508Z",
     "start_time": "2024-06-26T13:51:17.185377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download the file or the file is not a zip file.\n",
      "Status code: 406\n",
      "Content-Type: text/html; charset=iso-8859-1\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Initialize HTTP pool manager\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "# URL of the file to download\n",
    "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
    "\n",
    "# Path to save the downloaded file\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "\n",
    "# Download the file\n",
    "response = http.request('GET', url, preload_content=False)\n",
    "\n",
    "# Check if the response is successful and the content type is correct\n",
    "if response.status == 200 and response.headers['Content-Type'] == 'application/zip':\n",
    "    with open(zipfilename, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "    print(f\"Downloaded file saved as {zipfilename}\")\n",
    "\n",
    "    # Extract the zip file\n",
    "    try:\n",
    "        with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(path)\n",
    "        print(f\"Extracted files to {path}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(\"Failed to download the file or the file is not a zip file.\")\n",
    "    print(f\"Status code: {response.status}\")\n",
    "    print(f\"Content-Type: {response.headers.get('Content-Type')}\")\n",
    "\n",
    "# Release the HTTP response object\n",
    "response.release_conn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:51:47.269285Z",
     "start_time": "2024-06-26T13:51:46.900603Z"
    },
    "id": "6y9XPRYCiagc"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "\n",
    "zipfilename = os.path.join(path, filename)\n",
    "\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:52:17.231282Z",
     "start_time": "2024-06-26T13:52:17.217205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jkm20\\\\tensorflow-nlp-tutorial-main\\\\14. Seq2Seq (NMT)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:52:44.495296Z",
     "start_time": "2024-06-26T13:52:44.487338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jkm20\\\\tensorflow-nlp-tutorial-main\\\\14. Seq2Seq (NMT)\\\\fra-eng.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:50:14.145922Z",
     "start_time": "2024-06-26T13:50:13.105959Z"
    },
    "id": "6y9XPRYCiagc"
   },
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9d6a7567bf1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                 \u001b[1;31m# set the modified flag so central directory gets written\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File is not a zip file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File is not a zip file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T13:48:20.477546Z",
     "start_time": "2024-06-26T13:48:20.045Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdt-athJibxC",
    "outputId": "00cfd8b9-1232-442e-beb1-eec489b74da1"
   },
   "outputs": [],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "print('전체 샘플의 개수 :',len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "OJWHLXyricub",
    "outputId": "b4d78f5e-2cfa-434a-f0d4-b1c2e126658f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52521</th>\n",
       "      <td>What is your decision?</td>\n",
       "      <td>Quelle est ta décision ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30003</th>\n",
       "      <td>I'm not a pacifist.</td>\n",
       "      <td>Je ne suis pas pacifiste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31964</th>\n",
       "      <td>Tom is just joking.</td>\n",
       "      <td>Tom plaisante seulement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>Our team lost.</td>\n",
       "      <td>Notre équipe a perdu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54778</th>\n",
       "      <td>Here comes our teacher.</td>\n",
       "      <td>Voilà notre professeur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42235</th>\n",
       "      <td>I want some potatoes.</td>\n",
       "      <td>J'aimerais quelques pommes de terre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15871</th>\n",
       "      <td>Tom is an idiot.</td>\n",
       "      <td>Tom est idiot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59862</th>\n",
       "      <td>Why do you like horses?</td>\n",
       "      <td>Pourquoi aimez-vous les chevaux ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52096</th>\n",
       "      <td>Two seats were vacant.</td>\n",
       "      <td>Deux sièges étaient libres.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>He let me go.</td>\n",
       "      <td>Il m'a laissée partir.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                   tar\n",
       "52521   What is your decision?              Quelle est ta décision ?\n",
       "30003      I'm not a pacifist.             Je ne suis pas pacifiste.\n",
       "31964      Tom is just joking.              Tom plaisante seulement.\n",
       "8162            Our team lost.                 Notre équipe a perdu.\n",
       "54778  Here comes our teacher.               Voilà notre professeur.\n",
       "42235    I want some potatoes.  J'aimerais quelques pommes de terre.\n",
       "15871         Tom is an idiot.                        Tom est idiot.\n",
       "59862  Why do you like horses?     Pourquoi aimez-vous les chevaux ?\n",
       "52096   Two seats were vacant.           Deux sièges étaient libres.\n",
       "4646             He let me go.                Il m'a laissée partir."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "HC80PHpgidj6",
    "outputId": "793e8f2c-d0a3-4db0-c1b2-0f33a96762c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>May I interrupt?</td>\n",
       "      <td>\\t Puis-je t'interrompre ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20863</th>\n",
       "      <td>Tom was abducted.</td>\n",
       "      <td>\\t Tom était kidnappé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12952</th>\n",
       "      <td>Bring it closer.</td>\n",
       "      <td>\\t Rapprochez-la. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57103</th>\n",
       "      <td>Let me get back to you.</td>\n",
       "      <td>\\t Laissez-moi revenir vers vous ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45344</th>\n",
       "      <td>We speak French here.</td>\n",
       "      <td>\\t Nous parlons français ici. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>How many people died?</td>\n",
       "      <td>\\t Combien de personnes sont-elles décédées ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17726</th>\n",
       "      <td>He heard a noise.</td>\n",
       "      <td>\\t Il entendit un bruit. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19834</th>\n",
       "      <td>She defeated him.</td>\n",
       "      <td>\\t Elle l'a battu. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51857</th>\n",
       "      <td>Tom is making a video.</td>\n",
       "      <td>\\t Tom tourne une vidéo. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31941</th>\n",
       "      <td>Tom is fashionable.</td>\n",
       "      <td>\\t Tom est chic. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                               tar\n",
       "15057         May I interrupt?                     \\t Puis-je t'interrompre ? \\n\n",
       "20863        Tom was abducted.                         \\t Tom était kidnappé. \\n\n",
       "12952         Bring it closer.                              \\t Rapprochez-la. \\n\n",
       "57103  Let me get back to you.             \\t Laissez-moi revenir vers vous ! \\n\n",
       "45344    We speak French here.                  \\t Nous parlons français ici. \\n\n",
       "41103    How many people died?  \\t Combien de personnes sont-elles décédées ? \\n\n",
       "17726        He heard a noise.                       \\t Il entendit un bruit. \\n\n",
       "19834        She defeated him.                             \\t Elle l'a battu. \\n\n",
       "51857   Tom is making a video.                       \\t Tom tourne une vidéo. \\n\n",
       "31941      Tom is fashionable.                               \\t Tom est chic. \\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5VyYPo3iedy"
   },
   "outputs": [],
   "source": [
    "# 글자 집합 구축\n",
    "src_vocab = set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfg9pOB7ifgK",
    "outputId": "fd5eca24-ce9e-425f-ce37-37886f7860bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 char 집합 : 79\n",
      "target 문장의 char 집합 : 105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print('source 문장의 char 집합 :',src_vocab_size)\n",
    "print('target 문장의 char 집합 :',tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJJolPvRignC",
    "outputId": "52d760f9-1003-42be-8b0b-4cc769860fed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQusbB6GiiH7",
    "outputId": "35d3056b-5e38-4097-ecb6-f1927d56b9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OeHzq5rNijWS",
    "outputId": "186f24f9-4dd8-4633-f031-ee7ebe7dec28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10], [31, 58, 10]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "\n",
    "# 1개의 문장\n",
    "for line in lines.src:\n",
    "  encoded_line = []\n",
    "  # 각 줄에서 1개의 char\n",
    "  for char in line:\n",
    "    # 각 char을 정수로 변환\n",
    "    encoded_line.append(src_to_index[char])\n",
    "  encoder_input.append(encoded_line)\n",
    "print('source 문장의 정수 인코딩 :',encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MFjg8quikj6",
    "outputId": "31bd4e3f-1e8d-4ff5-d2c5-64929455cb44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장의 정수 인코딩 : [[1, 3, 48, 53, 3, 4, 3, 2], [1, 3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [1, 3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    encoded_line.append(tar_to_index[char])\n",
    "  decoder_input.append(encoded_line)\n",
    "print('target 문장의 정수 인코딩 :',decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6RS186uilqK",
    "outputId": "389b4b8f-45dc-4016-cb11-5f85d0df3738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 문장 레이블의 정수 인코딩 : [[3, 48, 53, 3, 4, 3, 2], [3, 39, 53, 70, 55, 60, 57, 14, 3, 2], [3, 28, 67, 73, 59, 57, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "  timestep = 0\n",
    "  encoded_line = []\n",
    "  for char in line:\n",
    "    if timestep > 0:\n",
    "      encoded_line.append(tar_to_index[char])\n",
    "    timestep = timestep + 1\n",
    "  decoder_target.append(encoded_line)\n",
    "print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Zlq71juimoy",
    "outputId": "92a28855-af9c-44f7-94ce-3ed0c067cb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source 문장의 최대 길이 : 23\n",
      "target 문장의 최대 길이 : 76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print('source 문장의 최대 길이 :',max_src_len)\n",
    "print('target 문장의 최대 길이 :',max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcnFgd9Zinsa"
   },
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcXSOrECio3C"
   },
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GqUpQ_Rippq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9blN5WziqtS"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "\n",
    "# encoder_outputs은 여기서는 불필요\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keZfw7g2irvK"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "\n",
    "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q82rA2Ixisor",
    "outputId": "83781e04-9947-479a-e690-e610299f7695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "750/750 [==============================] - 20s 19ms/step - loss: 0.7506 - val_loss: 0.6625\n",
      "Epoch 2/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.4580 - val_loss: 0.5342\n",
      "Epoch 3/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.3822 - val_loss: 0.4703\n",
      "Epoch 4/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.3395 - val_loss: 0.4339\n",
      "Epoch 5/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.3105 - val_loss: 0.4109\n",
      "Epoch 6/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2896 - val_loss: 0.3911\n",
      "Epoch 7/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2731 - val_loss: 0.3801\n",
      "Epoch 8/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2601 - val_loss: 0.3723\n",
      "Epoch 9/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.2491 - val_loss: 0.3662\n",
      "Epoch 10/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2398 - val_loss: 0.3601\n",
      "Epoch 11/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.2314 - val_loss: 0.3569\n",
      "Epoch 12/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.2241 - val_loss: 0.3551\n",
      "Epoch 13/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2175 - val_loss: 0.3528\n",
      "Epoch 14/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2115 - val_loss: 0.3527\n",
      "Epoch 15/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2059 - val_loss: 0.3506\n",
      "Epoch 16/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.2009 - val_loss: 0.3503\n",
      "Epoch 17/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1961 - val_loss: 0.3509\n",
      "Epoch 18/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1917 - val_loss: 0.3504\n",
      "Epoch 19/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1875 - val_loss: 0.3526\n",
      "Epoch 20/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1835 - val_loss: 0.3542\n",
      "Epoch 21/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1799 - val_loss: 0.3556\n",
      "Epoch 22/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1762 - val_loss: 0.3563\n",
      "Epoch 23/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1731 - val_loss: 0.3602\n",
      "Epoch 24/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1699 - val_loss: 0.3633\n",
      "Epoch 25/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1669 - val_loss: 0.3626\n",
      "Epoch 26/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1640 - val_loss: 0.3656\n",
      "Epoch 27/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1613 - val_loss: 0.3692\n",
      "Epoch 28/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1586 - val_loss: 0.3716\n",
      "Epoch 29/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1562 - val_loss: 0.3721\n",
      "Epoch 30/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1538 - val_loss: 0.3753\n",
      "Epoch 31/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1515 - val_loss: 0.3763\n",
      "Epoch 32/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1492 - val_loss: 0.3814\n",
      "Epoch 33/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1471 - val_loss: 0.3825\n",
      "Epoch 34/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1452 - val_loss: 0.3861\n",
      "Epoch 35/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1433 - val_loss: 0.3874\n",
      "Epoch 36/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1413 - val_loss: 0.3908\n",
      "Epoch 37/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1395 - val_loss: 0.3940\n",
      "Epoch 38/40\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.1378 - val_loss: 0.3989\n",
      "Epoch 39/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1362 - val_loss: 0.3995\n",
      "Epoch 40/40\n",
      "750/750 [==============================] - 13s 18ms/step - loss: 0.1344 - val_loss: 0.4027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96f7a05e50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvAzKE5divNi"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OssDkukziwpK",
    "outputId": "ae24f70f-035d-4f6b-acd4-897e6aede90e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 79)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 256),             344064    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 344,064\n",
      "Trainable params: 344,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnBYHCbOizSi"
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYMVxO_MgT-6"
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9WAlasJgVbK"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # 입력으로부터 인코더의 상태를 얻음\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "  target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "  target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = \"\"\n",
    "\n",
    "  # stop_condition이 True가 될 때까지 루프 반복\n",
    "  while not stop_condition:\n",
    "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 문자로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sentence += sampled_char\n",
    "\n",
    "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "    if (sampled_char == '\\n' or\n",
    "        len(decoded_sentence) > max_tar_len):\n",
    "        stop_condition = True\n",
    "\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGLAMcZSgWaq",
    "outputId": "ea6c2aad-dedc-46ef-b063-c14dd19d44ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Hi.\n",
      "정답 문장: Salut ! \n",
      "번역 문장: Salut. \n",
      "-----------------------------------\n",
      "입력 문장: I see.\n",
      "정답 문장: Aha. \n",
      "번역 문장: Je suis différente. \n",
      "-----------------------------------\n",
      "입력 문장: Hug me.\n",
      "정답 문장: Serrez-moi dans vos bras ! \n",
      "번역 문장: Serre-moi dans votre chambre ! \n",
      "-----------------------------------\n",
      "입력 문장: Help me.\n",
      "정답 문장: Aidez-moi. \n",
      "번역 문장: Aide-moi ! \n",
      "-----------------------------------\n",
      "입력 문장: I beg you.\n",
      "정답 문장: Je vous en prie. \n",
      "번역 문장: Je te supporais. \n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "  input_seq = encoder_input[seq_index:seq_index+1]\n",
    "  decoded_sentence = decode_sequence(input_seq)\n",
    "  print(35 * \"-\")\n",
    "  print('입력 문장:', lines.src[seq_index])\n",
    "  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "char-level seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
