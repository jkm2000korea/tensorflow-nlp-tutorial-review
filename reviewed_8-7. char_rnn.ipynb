{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:12.004811Z",
     "start_time": "2024-06-09T05:42:11.989201Z"
    }
   },
   "source": [
    "# 리뷰완료 2024.6.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbyOiS3y8Lpb"
   },
   "source": [
    "# 1. 글자 단위 RNN 언어 모델(Char RNNLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:44.590953Z",
     "start_time": "2024-06-09T05:42:29.742864Z"
    },
    "id": "cwFLoSSx5KlO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.418608Z",
     "start_time": "2024-06-09T05:42:44.590953Z"
    },
    "id": "6-PUxpHa5NpX"
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
    "f = open('11-0.txt', 'rb')\n",
    "sentences = []\n",
    "for sentence in f: # 데이터를 한 줄씩 읽는다.\n",
    "    sentence = sentence.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
    "    sentence = sentence.lower() # 소문자화.\n",
    "    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.448878Z",
     "start_time": "2024-06-09T05:42:46.423483Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKP7Zi2f5OcU",
    "outputId": "e2a670ca-9ce1-474e-9585-63f19aced020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"*** start of the project gutenberg ebook alice's adventures in\",\n",
       " 'wonderland ***',\n",
       " '[illustration]',\n",
       " 'alices adventures in wonderland',\n",
       " 'by lewis carroll']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.480667Z",
     "start_time": "2024-06-09T05:42:46.450875Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVccL5NL54i7",
    "outputId": "74d760eb-6b0c-41bf-b123-dbce346638a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열의 길이 또는 총 글자의 개수: 140323\n"
     ]
    }
   ],
   "source": [
    "total_data = ' '.join(sentences)\n",
    "print('문자열의 길이 또는 총 글자의 개수: %d' % len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.493269Z",
     "start_time": "2024-06-09T05:42:46.480667Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBoyjNpx6Zfi",
    "outputId": "43c1c51e-96e2-4ce5-b9b1-87aca44062c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** start of the project gutenberg ebook alice's adventures in wonderland *** [illustration] alices adventures in wonderland by lewis carroll the millennium fulcrum edition 3.0 contents chapter i.    \n"
     ]
    }
   ],
   "source": [
    "print(total_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.501531Z",
     "start_time": "2024-06-09T05:42:46.495272Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-Ttlxpl6abZ",
    "outputId": "7cfeb1cd-c54d-44ff-ab42-d517cf7e46e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "글자 집합의 크기 : 43\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(total_data)))\n",
    "vocab_size = len(char_vocab)\n",
    "print ('글자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.509732Z",
     "start_time": "2024-06-09T05:42:46.501531Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELPHZ-6W6dor",
    "outputId": "f2071f65-3dad-440e-ed09-63fcb0a21dac"
   },
   "source": [
    "# 글자를 정수(벡터가 아닌) 인덱스로 부여해주는 함수 정의 elaborated by paul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.509732Z",
     "start_time": "2024-06-09T05:42:46.501531Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELPHZ-6W6dor",
    "outputId": "f2071f65-3dad-440e-ed09-63fcb0a21dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, \"'\": 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '0': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.514850Z",
     "start_time": "2024-06-09T05:42:46.511868Z"
    },
    "id": "bsi1VHGO6hLz"
   },
   "outputs": [],
   "source": [
    "index_to_char={}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.530490Z",
     "start_time": "2024-06-09T05:42:46.514850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjR9VLzu6jjD",
    "outputId": "b1553c58-1eef-4dd0-d420-1c639fe348b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 샘플의 수 : 2338\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60 # 문장의 길이를 60으로 한다.\n",
    "n_samples = int(np.floor((len(total_data) - 1) / seq_length)) # 문자열을 60등분한다. 그러면 즉, 총 샘플의 개수\n",
    "print ('문장 샘플의 수 : {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.550618Z",
     "start_time": "2024-06-09T05:42:46.530490Z"
    },
    "id": "zdy4iRw56lPL"
   },
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 픽한다.\n",
    "    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n",
    "\n",
    "    # 정수 인코딩\n",
    "    X_encoded = [char_to_index[c] for c in X_sample]\n",
    "    train_X.append(X_encoded)\n",
    "\n",
    "    # 오른쪽으로 1칸 쉬프트\n",
    "    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    train_y.append(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.559748Z",
     "start_time": "2024-06-09T05:42:46.550618Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WShbQjlX64Iz",
    "outputId": "cf998df5-ded5-4556-a771-111fa65d1cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터의 첫번째 샘플 : [5, 5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0]\n",
      "y 데이터의 첫번째 샘플 : [5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25]\n",
      "--------------------------------------------------\n",
      "X 데이터의 첫번째 샘플 디코딩 : ['*', '*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ']\n",
      "y 데이터의 첫번째 샘플 디코딩 : ['*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i']\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터의 첫번째 샘플 :',train_X[0])\n",
    "print('y 데이터의 첫번째 샘플 :',train_y[0])\n",
    "print('-'*50)\n",
    "print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n",
    "print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.566265Z",
     "start_time": "2024-06-09T05:42:46.560777Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jsksKE17L6y",
    "outputId": "e57fa9ef-d8c7-486e-d21b-13aec531b7d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 30, 0, 39, 31, 30, 20, 21, 34, 28, 17, 30, 20, 0, 5, 5, 5, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31, 30, 15, 0, 17, 28, 25, 19, 21, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25, 30, 0, 39, 31, 30, 20, 21, 34]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.576536Z",
     "start_time": "2024-06-09T05:42:46.566265Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0487oJ67NZl",
    "outputId": "6dc7bff8-c18f-41ba-d83d-ed34cc3e66a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 0, 39, 31, 30, 20, 21, 34, 28, 17, 30, 20, 0, 5, 5, 5, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31, 30, 15, 0, 17, 28, 25, 19, 21, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25, 30, 0, 39, 31, 30, 20, 21, 34, 28]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.612048Z",
     "start_time": "2024-06-09T05:42:46.577538Z"
    },
    "id": "TnGMrM1k7OKi"
   },
   "outputs": [],
   "source": [
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:46.628668Z",
     "start_time": "2024-06-09T05:42:46.613349Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipt5Vbf_7bCD",
    "outputId": "6f7f9fcc-835b-4bd7-f517-ce89d1c85d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X의 크기(shape) : (2338, 60, 43)\n",
      "train_y의 크기(shape) : (2338, 60, 43)\n"
     ]
    }
   ],
   "source": [
    "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
    "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T05:42:47.095147Z",
     "start_time": "2024-06-09T05:42:46.630596Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHsf4lJm7cAj",
    "outputId": "f49b8558-ac79-49ed-a2ca-b87c1637058d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 256)         307200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 256)         525312    \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, 43)          11051     \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 843563 (3.22 MB)\n",
      "Trainable params: 843563 (3.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "hidden_units = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlPjFFJq7jcr",
    "outputId": "de0e9853-d981-4e9e-9cd7-e0dfb72b6b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "74/74 - 27s - loss: 3.0260 - accuracy: 0.1888 - 27s/epoch - 362ms/step\n",
      "Epoch 2/80\n",
      "74/74 - 32s - loss: 2.6697 - accuracy: 0.2617 - 32s/epoch - 435ms/step\n",
      "Epoch 3/80\n",
      "74/74 - 33s - loss: 2.3229 - accuracy: 0.3424 - 33s/epoch - 443ms/step\n",
      "Epoch 4/80\n",
      "74/74 - 33s - loss: 2.1828 - accuracy: 0.3783 - 33s/epoch - 443ms/step\n",
      "Epoch 5/80\n",
      "74/74 - 33s - loss: 2.0706 - accuracy: 0.4055 - 33s/epoch - 452ms/step\n",
      "Epoch 6/80\n",
      "74/74 - 35s - loss: 1.9890 - accuracy: 0.4254 - 35s/epoch - 478ms/step\n",
      "Epoch 7/80\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=80, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.765Z"
    },
    "id": "8lX31r2y7lbY"
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    # 글자에 대한 랜덤 인덱스 생성\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "\n",
    "    # 랜덤 익덱스로부터 글자 생성\n",
    "    y_char = [index_to_char[ix[-1]]]\n",
    "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
    "\n",
    "    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "\n",
    "    for i in range(length):\n",
    "        # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
    "        X[0][i][ix[-1]] = 1\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgSKvzAE7zaD",
    "outputId": "cd27625e-3921-4e8d-d1f8-57c1bc66d912"
   },
   "outputs": [],
   "source": [
    "result = sentence_generation(model, 100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjb93Az58QIO"
   },
   "source": [
    "# 2. 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMMHgEPr8R1n"
   },
   "source": [
    "이번에는 다 대 일(many-to-one) 구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성을 해보겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.767Z"
    },
    "id": "D7PwoCcN7-rL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.767Z"
    },
    "id": "2D_GYxw28S6c"
   },
   "outputs": [],
   "source": [
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.768Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "823KE-Oh8Uoa",
    "outputId": "26f69b62-dab2-459d-ceb8-124206afe020"
   },
   "outputs": [],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = ' '.join(tokens)\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.768Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rfxe6-xO8WIE",
    "outputId": "ba12d8b3-b6eb-46af-a06a-6eda7f34a8b3"
   },
   "outputs": [],
   "source": [
    "# 중복을 제거한 글자 집합 생성\n",
    "char_vocab = sorted(list(set(raw_text)))\n",
    "print(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.769Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVf-hgG18Zv0",
    "outputId": "95185a97-d74c-447e-fdba-2379b2fa8eaf"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(char_vocab)\n",
    "print ('글자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.770Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AA1ctt5t8eRa",
    "outputId": "8b758eb7-0dd0-473d-b1c2-4257461b1b47"
   },
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.770Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EiZW1obf8eaE",
    "outputId": "6d0bfa55-1fe6-458b-e194-4904f7310148"
   },
   "outputs": [],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
    "    sequences.append(seq)\n",
    "print('총 훈련 샘플의 수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.771Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ait_ciP98hD8",
    "outputId": "8f4d7976-6265-499e-cb96-ac24ad4e50e5"
   },
   "outputs": [],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.772Z"
    },
    "id": "bhiQ6Uq58iD6"
   },
   "outputs": [],
   "source": [
    "encoded_sequences = []\n",
    "for sequence in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
    "    encoded_sequence = [char_to_index[char] for char in sequence] # 문장 샘플에서 각 글자에 대해서 정수 인코딩을 수행.\n",
    "    encoded_sequences.append(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.772Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lz1bV5D_1rWu",
    "outputId": "cabc0304-5bc7-4ab0-eabc-64294262a5b4"
   },
   "outputs": [],
   "source": [
    "encoded_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.773Z"
    },
    "id": "3f5fQ9Wc1w_t"
   },
   "outputs": [],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)\n",
    "X_data = encoded_sequences[:,:-1]\n",
    "\n",
    "# 맨 마지막 위치의 글자를 분리\n",
    "y_data = encoded_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.773Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s--PreVs1-Sd",
    "outputId": "18f3dd0a-8a70-4eff-93fa-add9c6704613"
   },
   "outputs": [],
   "source": [
    "print(X_data[:5])\n",
    "print(y_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.774Z"
    },
    "id": "q_CQgpkw2Hc4"
   },
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
    "X_data_one_hot = np.array(X_data_one_hot)\n",
    "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.774Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y5NEsRym2bBo",
    "outputId": "7e8f9900-fea1-43aa-8dc5-5097c398fa6b"
   },
   "outputs": [],
   "source": [
    "print(X_data_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.775Z"
    },
    "id": "8CqLyAsG2dP9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.776Z"
    },
    "id": "LiqNlvRu2egu"
   },
   "outputs": [],
   "source": [
    "hidden_units = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.776Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymJjEjd42i_l",
    "outputId": "61ecaef0-463d-4304-8c01-67b7c328f461"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.777Z"
    },
    "id": "m8hZiN9Y2oH-"
   },
   "outputs": [],
   "source": [
    "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
    "\n",
    "    # 초기 시퀀스\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "\n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
    "\n",
    "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 글자)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "        \n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 시퀀스 + 예측 글자를 현재 시퀀스로 변경\n",
    "        seed_text = seed_text + char\n",
    "\n",
    "        # 예측 글자를 문장에 저장\n",
    "        sentence = sentence + char\n",
    "\n",
    "    sentence = init_text + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-09T05:42:29.777Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5kIEaBq2833",
    "outputId": "2ca28b55-d865-4ee2-b113-1ec86c3fea5d"
   },
   "outputs": [],
   "source": [
    "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Char RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
