{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리뷰완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GBW64BCOofy"
   },
   "source": [
    "이 자료는 위키독스 딥 러닝을 이용한 자연어 처리 입문의 자동 미분과 선형 회귀 튜토리얼입니다.  \n",
    "\n",
    "링크 : https://wikidocs.net/111472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUW8bf-sSkbO"
   },
   "source": [
    "# 1. 자동 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:21:52.458656Z",
     "start_time": "2024-05-24T13:21:37.155706Z"
    },
    "id": "p6FWvMAPNM73"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:21:53.301039Z",
     "start_time": "2024-05-24T13:21:53.293063Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gXnpYeOBNPst",
    "outputId": "e9c59450-6d3e-414a-b519-721bc894af04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:22:02.589204Z",
     "start_time": "2024-05-24T13:22:02.503347Z"
    },
    "id": "BNnzmU5WNQyk"
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:22:09.039690Z",
     "start_time": "2024-05-24T13:22:09.015420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:22:43.522098Z",
     "start_time": "2024-05-24T13:22:43.515537Z"
    },
    "id": "BNnzmU5WNQyk"
   },
   "outputs": [],
   "source": [
    "def f(w):\n",
    "  y = w**2 # 2**2 = y= 4\n",
    "  z = 2*y + 5 #2*4+5=13 =z \n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:23:02.409911Z",
     "start_time": "2024-05-24T13:23:02.369191Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51Y6C6xfNR_s",
    "outputId": "3d56532b-654d-4fb8-ac0d-f7734bdc97d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  z = f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRwwF03lSoBy"
   },
   "source": [
    "# 2. 자동 미분을 이용한 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:24:02.641305Z",
     "start_time": "2024-05-24T13:24:02.625987Z"
    },
    "id": "zK0aP09pNStk"
   },
   "outputs": [],
   "source": [
    "# 학습될 가중치 변수를 선언\n",
    "W = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:24:03.838339Z",
     "start_time": "2024-05-24T13:24:03.824572Z"
    },
    "id": "hV4Z5l3yNTfs"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hypothesis(x):\n",
    "  return W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:24:53.973476Z",
     "start_time": "2024-05-24T13:24:53.821456Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wskrej1QNUP0",
    "outputId": "3a30d9c8-5779-48f1-f0ad-6f31fe66b089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 21. 23. 25.]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy()) #3.4*4+1=15, 5*4+1=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:25:07.494157Z",
     "start_time": "2024-05-24T13:25:07.488819Z"
    },
    "id": "8xmmgZ90NVIr"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "  # 두 개의 차이값을 제곱을 해서 평균을 취한다.\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:25:17.858203Z",
     "start_time": "2024-05-24T13:25:17.849858Z"
    },
    "id": "qRI9TWU-NWcE"
   },
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:25:18.428829Z",
     "start_time": "2024-05-24T13:25:18.404681Z"
    },
    "id": "YTsCMtv4NbCT"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:26:32.481321Z",
     "start_time": "2024-05-24T13:26:31.637538Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxeO-C8mNb7T",
    "outputId": "e39711e5-affc-43e6-cf81-53ab01fe6db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0 | W의 값 : 10.6671 | b의 값 : 0.908 | cost : 1.062102\n",
      "epoch :  10 | W의 값 : 10.6677 | b의 값 : 0.9039 | cost : 1.061931\n",
      "epoch :  20 | W의 값 : 10.6683 | b의 값 : 0.8999 | cost : 1.061765\n",
      "epoch :  30 | W의 값 : 10.6689 | b의 값 : 0.8961 | cost : 1.061616\n",
      "epoch :  40 | W의 값 : 10.6695 | b의 값 : 0.8924 | cost : 1.061478\n",
      "epoch :  50 | W의 값 : 10.6701 | b의 값 : 0.8889 | cost : 1.061354\n",
      "epoch :  60 | W의 값 : 10.6706 | b의 값 : 0.8856 | cost : 1.061237\n",
      "epoch :  70 | W의 값 : 10.6711 | b의 값 : 0.8824 | cost : 1.061131\n",
      "epoch :  80 | W의 값 : 10.6716 | b의 값 : 0.8793 | cost : 1.061027\n",
      "epoch :  90 | W의 값 : 10.6721 | b의 값 : 0.8763 | cost : 1.060937\n",
      "epoch : 100 | W의 값 : 10.6725 | b의 값 : 0.8734 | cost : 1.060852\n",
      "epoch : 110 | W의 값 : 10.6730 | b의 값 : 0.8707 | cost : 1.060777\n",
      "epoch : 120 | W의 값 : 10.6734 | b의 값 : 0.8681 | cost : 1.060702\n",
      "epoch : 130 | W의 값 : 10.6738 | b의 값 : 0.8655 | cost : 1.060640\n",
      "epoch : 140 | W의 값 : 10.6742 | b의 값 : 0.8631 | cost : 1.060583\n",
      "epoch : 150 | W의 값 : 10.6746 | b의 값 : 0.8608 | cost : 1.060523\n",
      "epoch : 160 | W의 값 : 10.6749 | b의 값 : 0.8586 | cost : 1.060475\n",
      "epoch : 170 | W의 값 : 10.6752 | b의 값 : 0.8564 | cost : 1.060429\n",
      "epoch : 180 | W의 값 : 10.6756 | b의 값 : 0.8544 | cost : 1.060382\n",
      "epoch : 190 | W의 값 : 10.6759 | b의 값 : 0.8524 | cost : 1.060344\n",
      "epoch : 200 | W의 값 : 10.6762 | b의 값 : 0.8505 | cost : 1.060305\n",
      "epoch : 210 | W의 값 : 10.6765 | b의 값 : 0.8487 | cost : 1.060272\n",
      "epoch : 220 | W의 값 : 10.6768 | b의 값 : 0.847 | cost : 1.060245\n",
      "epoch : 230 | W의 값 : 10.6770 | b의 값 : 0.8453 | cost : 1.060210\n",
      "epoch : 240 | W의 값 : 10.6773 | b의 값 : 0.8437 | cost : 1.060186\n",
      "epoch : 250 | W의 값 : 10.6775 | b의 값 : 0.8422 | cost : 1.060160\n",
      "epoch : 260 | W의 값 : 10.6777 | b의 값 : 0.8407 | cost : 1.060138\n",
      "epoch : 270 | W의 값 : 10.6780 | b의 값 : 0.8393 | cost : 1.060120\n",
      "epoch : 280 | W의 값 : 10.6782 | b의 값 : 0.8379 | cost : 1.060100\n",
      "epoch : 290 | W의 값 : 10.6784 | b의 값 : 0.8366 | cost : 1.060077\n",
      "epoch : 300 | W의 값 : 10.6786 | b의 값 : 0.8354 | cost : 1.060062\n"
     ]
    }
   ],
   "source": [
    "for i in range(301):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # 현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
    "    y_pred = hypothesis(x)\n",
    "\n",
    "    # 평균 제곱 오차를 계산\n",
    "    cost = mse_loss(y_pred, y)\n",
    "\n",
    "  # 손실 함수에 대한 파라미터의 미분값 계산\n",
    "  gradients = tape.gradient(cost, [W, b])\n",
    "\n",
    "  # 파라미터 업데이트\n",
    "  optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "  if i % 10 == 0:\n",
    "    print(\"epoch : {:3} | W의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:26:37.810020Z",
     "start_time": "2024-05-24T13:26:37.802516Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0UZ5FPSNc1L",
    "outputId": "9e6d7d17-5b1e-40a8-96d4-bd2be505c35a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.21045  54.228344 59.567642 64.906944]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2x8w6WHSqh8"
   },
   "source": [
    "# 3. 케라스로 구현하는 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:26:41.906993Z",
     "start_time": "2024-05-24T13:26:40.893292Z"
    },
    "id": "UarmrJMbNeIj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:26:50.264193Z",
     "start_time": "2024-05-24T13:26:42.690338Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNqDWT86NfgD",
    "outputId": "44e97211-6b68-41dd-949c-7b1e684ff976"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 4275.2510 - mse: 4275.2510\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 527.1484 - mse: 527.1484\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 65.9709 - mse: 65.9709\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.2250 - mse: 9.2250\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2414 - mse: 2.2414\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3806 - mse: 1.3806\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2733 - mse: 1.2733\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2587 - mse: 1.2587\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2554 - mse: 1.2554\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2536 - mse: 1.2536\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2520 - mse: 1.2520\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2505 - mse: 1.2505\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2489 - mse: 1.2489\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2473 - mse: 1.2473\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2458 - mse: 1.2458\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2443 - mse: 1.2443\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2428 - mse: 1.2428\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2413 - mse: 1.2413\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2398 - mse: 1.2398\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 582us/step - loss: 1.2383 - mse: 1.2383\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2368 - mse: 1.2368\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2354 - mse: 1.2354\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2340 - mse: 1.2340\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2325 - mse: 1.2325\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2311 - mse: 1.2311\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2297 - mse: 1.2297\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2283 - mse: 1.2283\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2269 - mse: 1.2269\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2256 - mse: 1.2256\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2242 - mse: 1.2242\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2229 - mse: 1.2229\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2215 - mse: 1.2215\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2202 - mse: 1.2202\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2189 - mse: 1.2189\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2176 - mse: 1.2176\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2163 - mse: 1.2163\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2150 - mse: 1.2150\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2137 - mse: 1.2137\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2125 - mse: 1.2125\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2112 - mse: 1.2112\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2100 - mse: 1.2100\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2088 - mse: 1.2088\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2075 - mse: 1.2075\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2063 - mse: 1.2063\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2051 - mse: 1.2051\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2039 - mse: 1.2039\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2027 - mse: 1.2027\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2016 - mse: 1.2016\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2004 - mse: 1.2004\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1993 - mse: 1.1993\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1981 - mse: 1.1981\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1970 - mse: 1.1970\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1959 - mse: 1.1959\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1947 - mse: 1.1947\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1936 - mse: 1.1936\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1925 - mse: 1.1925\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1915 - mse: 1.1915\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1904 - mse: 1.1904\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1893 - mse: 1.1893\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1882 - mse: 1.1882\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1872 - mse: 1.1872\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1862 - mse: 1.1862\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1851 - mse: 1.1851\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1841 - mse: 1.1841\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1831 - mse: 1.1831\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1821 - mse: 1.1821\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1811 - mse: 1.1811\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1801 - mse: 1.1801\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1791 - mse: 1.1791\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1781 - mse: 1.1781\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1771 - mse: 1.1771\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1762 - mse: 1.1762\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1752 - mse: 1.1752\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1743 - mse: 1.1743\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1733 - mse: 1.1733\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1724 - mse: 1.1724\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1715 - mse: 1.1715\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1706 - mse: 1.1706\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1697 - mse: 1.1697\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1688 - mse: 1.1688\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1679 - mse: 1.1679\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1670 - mse: 1.1670\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1661 - mse: 1.1661\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1652 - mse: 1.1652\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1644 - mse: 1.1644\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1635 - mse: 1.1635\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1627 - mse: 1.1627\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1618 - mse: 1.1618\n",
      "Epoch 89/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.1610 - mse: 1.1610\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1602 - mse: 1.1602\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1593 - mse: 1.1593\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1585 - mse: 1.1585\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1577 - mse: 1.1577\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1569 - mse: 1.1569\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1561 - mse: 1.1561\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1553 - mse: 1.1553\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1545 - mse: 1.1545\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1538 - mse: 1.1538\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1530 - mse: 1.1530\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 830us/step - loss: 1.1522 - mse: 1.1522\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1515 - mse: 1.1515\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1507 - mse: 1.1507\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1500 - mse: 1.1500\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1492 - mse: 1.1492\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1485 - mse: 1.1485\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1478 - mse: 1.1478\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1471 - mse: 1.1471\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1464 - mse: 1.1464\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1456 - mse: 1.1456\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1449 - mse: 1.1449\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1442 - mse: 1.1442\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1435 - mse: 1.1435\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1429 - mse: 1.1429\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1422 - mse: 1.1422\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1415 - mse: 1.1415\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1408 - mse: 1.1408\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1402 - mse: 1.1402\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1395 - mse: 1.1395\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1389 - mse: 1.1389\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1382 - mse: 1.1382\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1376 - mse: 1.1376\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1369 - mse: 1.1369\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1363 - mse: 1.1363\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1357 - mse: 1.1357\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1351 - mse: 1.1351\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1344 - mse: 1.1344\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1338 - mse: 1.1338\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1332 - mse: 1.1332\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1326 - mse: 1.1326\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1320 - mse: 1.1320\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1314 - mse: 1.1314\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1308 - mse: 1.1308\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1303 - mse: 1.1303\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1297 - mse: 1.1297\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1291 - mse: 1.1291\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1285 - mse: 1.1285\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1280 - mse: 1.1280\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1274 - mse: 1.1274\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1269 - mse: 1.1269\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1263 - mse: 1.1263\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1258 - mse: 1.1258\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1252 - mse: 1.1252\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1247 - mse: 1.1247\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1242 - mse: 1.1242\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1236 - mse: 1.1236\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 1.1231 - mse: 1.1231\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1226 - mse: 1.1226\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1221 - mse: 1.1221\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1216 - mse: 1.1216\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1211 - mse: 1.1211\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1206 - mse: 1.1206\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1201 - mse: 1.1201\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1196 - mse: 1.1196\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1191 - mse: 1.1191\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1186 - mse: 1.1186\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1181 - mse: 1.1181\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1176 - mse: 1.1176\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1172 - mse: 1.1172\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1167 - mse: 1.1167\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1162 - mse: 1.1162\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1158 - mse: 1.1158\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1153 - mse: 1.1153\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1149 - mse: 1.1149\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1144 - mse: 1.1144\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1140 - mse: 1.1140\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1135 - mse: 1.1135\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1131 - mse: 1.1131\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1126 - mse: 1.1126\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1122 - mse: 1.1122\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1118 - mse: 1.1118\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 179us/step - loss: 1.1114 - mse: 1.1114\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1109 - mse: 1.1109\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1105 - mse: 1.1105\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1101 - mse: 1.1101\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1097 - mse: 1.1097\n",
      "Epoch 176/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1093 - mse: 1.1093\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1089 - mse: 1.1089\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1085 - mse: 1.1085\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1081 - mse: 1.1081\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1077 - mse: 1.1077\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1073 - mse: 1.1073\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1069 - mse: 1.1069\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1065 - mse: 1.1065\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1061 - mse: 1.1061\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1058 - mse: 1.1058\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1054 - mse: 1.1054\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1050 - mse: 1.1050\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1046 - mse: 1.1046\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1043 - mse: 1.1043\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1039 - mse: 1.1039\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1035 - mse: 1.1035\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1032 - mse: 1.1032\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1028 - mse: 1.1028\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1025 - mse: 1.1025\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1021 - mse: 1.1021\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1018 - mse: 1.1018\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1014 - mse: 1.1014\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1011 - mse: 1.1011\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1008 - mse: 1.1008\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1004 - mse: 1.1004\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 375us/step - loss: 1.1001 - mse: 1.1001\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0998 - mse: 1.0998\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0994 - mse: 1.0994\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0991 - mse: 1.0991\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0988 - mse: 1.0988\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0985 - mse: 1.0985\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0982 - mse: 1.0982\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0978 - mse: 1.0978\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0975 - mse: 1.0975\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0972 - mse: 1.0972\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0969 - mse: 1.0969\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0966 - mse: 1.0966\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0963 - mse: 1.0963\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0960 - mse: 1.0960\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0957 - mse: 1.0957\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0954 - mse: 1.0954\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0951 - mse: 1.0951\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0948 - mse: 1.0948\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0946 - mse: 1.0946\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0943 - mse: 1.0943\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0940 - mse: 1.0940\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0937 - mse: 1.0937\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0934 - mse: 1.0934\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0932 - mse: 1.0932\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0929 - mse: 1.0929\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0926 - mse: 1.0926\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0923 - mse: 1.0923\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0921 - mse: 1.0921\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0918 - mse: 1.0918\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0916 - mse: 1.0916\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0913 - mse: 1.0913\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0910 - mse: 1.0910\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0908 - mse: 1.0908\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0905 - mse: 1.0905\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0903 - mse: 1.0903\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0900 - mse: 1.0900\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0898 - mse: 1.0898\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0895 - mse: 1.0895\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0893 - mse: 1.0893\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0890 - mse: 1.0890\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0888 - mse: 1.0888\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0886 - mse: 1.0886\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0883 - mse: 1.0883\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0881 - mse: 1.0881\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0879 - mse: 1.0879\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0876 - mse: 1.0876\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0874 - mse: 1.0874\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0872 - mse: 1.0872\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0870 - mse: 1.0870\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0867 - mse: 1.0867\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0865 - mse: 1.0865\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0863 - mse: 1.0863\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0861 - mse: 1.0861\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0859 - mse: 1.0859\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0857 - mse: 1.0857\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0854 - mse: 1.0854\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0852 - mse: 1.0852\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0850 - mse: 1.0850\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0848 - mse: 1.0848\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0846 - mse: 1.0846\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0844 - mse: 1.0844\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0842 - mse: 1.0842\n",
      "Epoch 263/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.0840 - mse: 1.0840\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0838 - mse: 1.0838\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0836 - mse: 1.0836\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0834 - mse: 1.0834\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0832 - mse: 1.0832\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0830 - mse: 1.0830\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0829 - mse: 1.0829\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0827 - mse: 1.0827\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 911us/step - loss: 1.0825 - mse: 1.0825\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0823 - mse: 1.0823\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0821 - mse: 1.0821\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0819 - mse: 1.0819\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0817 - mse: 1.0817\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0816 - mse: 1.0816\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0814 - mse: 1.0814\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0812 - mse: 1.0812\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0810 - mse: 1.0810\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0809 - mse: 1.0809\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0807 - mse: 1.0807\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0805 - mse: 1.0805\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0804 - mse: 1.0804\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0802 - mse: 1.0802\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0800 - mse: 1.0800\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0799 - mse: 1.0799\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0797 - mse: 1.0797\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0795 - mse: 1.0795\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0794 - mse: 1.0794\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0792 - mse: 1.0792\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0790 - mse: 1.0790\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0789 - mse: 1.0789\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0787 - mse: 1.0787\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0786 - mse: 1.0786\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0784 - mse: 1.0784\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0783 - mse: 1.0783\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0781 - mse: 1.0781\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0780 - mse: 1.0780\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0778 - mse: 1.0778\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0777 - mse: 1.0777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1872b24cf40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 시간\n",
    "y = [11, 22, 33, 44, 53, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 입력 x의 차원은 1, 출력 y의 차원도 1. 선형 회귀이므로 activation은 'linear'\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# sgd는 경사 하강법을 의미. 학습률(learning rate, lr)은 0.01.\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용합니다.\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "\n",
    "# 주어진 x와 y데이터에 대해서 오차를 최소화하는 작업을 300번 시도합니다.\n",
    "model.fit(x, y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T13:26:50.546723Z",
     "start_time": "2024-05-24T13:26:50.265458Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "GowvMQMUNht7",
    "outputId": "6c9e109b-a52f-4697-b39e-a289791ae4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1872b2ef2b0>,\n",
       " <matplotlib.lines.Line2D at 0x1872b2ef4c0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "자동 미분과 선형 회귀.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
